#  自然环境下语音情感识别综述

**Md. Shah Fahada,Ashish Ranjana, Jainath Yadavb, Akshay Deepaka 2021**



##  摘要

语音情感识别是近三十年来一个活跃的研究领域，而处理自然环境的技术是近十年才出现的。这些技术减少了训练和测试数据分布的不匹配，这种不匹配是由于训练和测试数据集之间的说话者、文本、语言和记录环境的差异而产生的。虽然有一些关于SER的好的调查，但是它们要么没有涵盖自然环境中SER的所有方面，要么没有详细讨论细节。这项调查侧重于自然环境中的SER，讨论了自然环境中的SER技术以及它们在说话者、文本、语言和记录环境方面的优缺点。在最近的过去，由于最小的语音处理和增强的准确性，深度学习技术变得非常流行。本调查特别关注深度学习技术和相关问题。最近的数据库，功能，和功能选择算法的SER，这些都没有在现有的调查中讨论过，可以在自然环境中有希望的SER，也在本文中进行了讨论。



## 1. 简介

情感在现实生活中扮演着重要的角色。一个人的情感可以通过各种信息源来识别，例如语音，成绩单，面部表情，脑信号（EEG）以及这些中的两个或多个的组合（称为多模式情感识别）。在这些来源中，可以说语音是最容易获得的。不管是说话者的身体运动还是由于玻璃，胡须，胡须等引起的视觉遮挡，与面部表情相比，语音属性几乎不受这些影响，或者不受面部表情的影响。在所有语言中，用于情感识别的语音（声学）功能几乎相似，并且可以在所有语言中使用相同的分类模型[1]。即使对大多数主要语言都执行了SER，但相同的模型也可以以可接受的精度用于其他语言。但是，对于语言功能而言并非如此。每种语言都需要特定的数据库。将此与需要特定语言模型的语言功能进行比较，这对于那些尚不具备标签情感数据的较不流行或区域性语言来说通常是一个障碍。即使有标记的数据可用，也需要构建特定于语言的模型，这显然是开销。



自动SER用于多种应用。它增强了人机交互（HCI）系统，例如交互式电影[2]，讲故事和电子教学应用程序[3]，以及视频/音频文件的检索和索引[4]。基于语音的情感识别系统有助于提高呼叫中心的呼叫服务员的服务质量[5]。自动情绪检测可以在[6]，[7]，[8]中使用的心理治疗中有所帮助。在监视系统的情况下它也很有用[9]。基于现代语音的系统主要使用中性语音进行设计。在这里，情感的组成部分可以用作附件，以提高实际应用中的准确性。如今，语音辅助搜索引擎已变得非常流行。对于在线市场，根据用户的情感（通过语音检测）动态更新网页将是有益的。



通过基于数字信号处理和机器学习的方法开发，可以实现自动语音情感识别（SER）。该领域的研究历时长达三十年。但是，结果仍不足以在高精度的自然环境中应用。语音信号中存在大量信息。语音信号包含词汇内容（说过的话），说话者（说过话的人），情感（说过话）和语言（说过的语言）。如果必须识别语音中的特定信息，则理想情况下应消除其他信息的影响。例如，如果必须从语音中识别出情感，那么理想情况下，说话人，词汇内容和语言的影响应该被消除，以概括SER系统。这是自动SER系统在现实生活中无法很好运行的主要原因。出现此问题的原因是，训练和测试数据中的说话者，文本，语言和文化（统称为“环境”）不匹配。结果，在实际应用或“自然环境”中，准确性会大大降低。在这里，“自然”是指SER系统的开发和部署环境之内和之间，说话者，文本，语言，文化，环境等的变化。



为了应对这一挑战，研究人员专注于独立的环境进行培训和测试。具体来说，这意味着说话者独立性[18–20]（使用不同的说话者进行培训和测试），文本独立性[21–24]（使用不同的成绩单进行培训和测试）和语言独立性[25–27]（使用不同的语言用于培训和测试（即跨语料库）。其中，跨语料库实验[25-27]更为流行，因为默认情况下，每个语料库中与说话者，文本和语言有关的信息都是不同的。提出了各种方法来解决这些问题。本调查重点介绍了这些技术以及它们的优缺点。另一类不匹配与记录环境的变化有关。这种不匹配是由不同类型的噪声，数据压缩，麦克风距离的变化以及通道不匹配引起的。为了解决记录环境的不匹配问题，近来，已经提出了各种噪声补偿技术和其他方法。在本次调查中，对这些技术进行了全面的研究，并提供了它们的优缺点。



SER中有一些不错的调查[10,11,13–17,28]。表1比较了针对SER不同方面与本文进行的现有调查。现有调查讨论了SER的基本组成部分：（1）数据库，（2）特征，（3）特征选择和（4）分类器。舒勒等 [10]从数据库到评估技术的端到端调查。在他们的论文中，已经将情感识别的任务作为分类和回归问题进行了讨论。已经详细讨论了数据库，特征和特征选择技术。他们的调查解释了评估SER模型的各种技术。他们的论文还重点介绍了与SER在嘈杂和跨主体环境中的鲁棒性相关的研究问题，但没有讨论这些方法。



Koolagudi和Rao[28]对数据库，功能和分类器进行了调查。他们将数据库分类为行为，引发和自然类别。他们讨论了自己的优缺点。他们将特征分为兴奋，声带和韵律特征。他们研究了组合不同功能的效果。还针对SER讨论了不同的分类方法及其组合。他们没有讨论SER的当前新兴的深度学习技术和问题。他们没有讨论应对自然环境的问题和技术。



Ayadi等 [11]描述了数据库，功能和分类器。他们的调查简要讨论了数据库。他们的调查的另一个不同而有用的方面是对时间（本地与全局）和源（连续，定性，频谱和基于TEO的要素）进行分类。调查还涉及将语音特征与语言，面部，视频和话语特征相结合以提高情感识别准确性的讨论。他们没有专注于深度学习技术和与SER相关的问题。他们也没有讨论当前的关注点，例如SER的自然环境。



Anagnostopoulos等[13]在2000年至2011年期间，对SER的研究进行了一项调查，他们提出了SER的总体规划。他们强调了将语音（声学）功能与语言和非语言发声功能（笑，哭，叹息，打哈欠等）结合使用来进行情感识别。讨论了分类器，整体学习和投票技术相结合对于情感识别的重要性。特征选择算法也进行了一定程度的讨论。它们没有涵盖SER当前的关注重点，例如自然环境。



Swain等人[14]研究了SER的数据库、特征和分类器技术。他们将特征分类为韵律、兴奋、声道，以及用于情感识别的一个或多个特征的融合。他们的论文还强调了深度学习、混合和融合技术在情感分类中的用处。Mustafa等人[15]研究了2006 - 2017年的文章。他们指出并讨论了当前用户服务的焦点是跨语言和实时用户服务。然而，他们并没有讨论处理跨语言和实时SER问题的技术。



舒勒等人[16]在一个简短的调查中讨论了传统的和当前的SER系统的方法。他们重点讨论了端到端SER系统，并讨论了当前来自不同语言和文化的SER挑战。但是，他们没有讨论端到端系统以及自然环境的相关问题和技术。



Akçay等 [17]在SER上进行的一项调查涵盖了SER的几乎所有领域，情感模型，数据库，功能，支持方式和分类器。在他们的论文中，他们讨论了深度学习分类器和基于深度学习的增强技术，例如自动编码器，多任务处理，对抗训练，对细节的关注。但是他们没有讨论有关SER的问题。他们专注于深度学习技术，但没有讨论与自然环境有关的技术。



现有的调查文件和当前的调查已经按照表1中的以下属性进行了分类：（1）数据库，（2）特征，（3）特征选择，（4）分类器，（5）深度学习，（6）与说话者无关的SER，（7）与文本无关的SER，（8）与语言无关的SER和（9）在不受控制的环境中的SER。



现有的研究讨论了流行的数据库，但是错过了一些最近开发的具有挑战性的自然数据库[29-32]。本文突出了从自然数据库开发SER模型的原因和可能的解决方案。现有的研究讨论的是SER常用的功能，但错过了最近提出的基于小波的，非线性和其他功能（在第4.2.1节中讨论）。本文的研究包括这些功能，并建议哪些功能适合哪种情感类别。有一些调查讨论了特征选择对语音情感识别的重要性。本文讨论了已被其他应用程序采用的，用于情感识别的特征选择算法，以及专门为情感识别而设计的算法。现有的大多数调查都讨论了传统的分类器，例如支持向量机（SVM），隐马尔可夫模型（HMM）等。一些调查讨论了深度学习方法，但没有讨论与语音情感识别相关的问题。由于深度学习方法取得了巨大的成功，这种方法最大程度地减少了语音处理的需求，因此需要对它们进行详细讨论。在这项调查中，详细讨论了用于语音情感识别的深度学习方法及其问题。一些调查强调了SER的当前关注点，例如跨语言SER和嘈杂环境中的SER。但是，本次调查详细讨论了有关问题和技术的当前研究重点，例如不匹配的环境（与扬声器无关的SER，与文本无关的SER和与语言无关的SER）和不受控制的元素（嘈杂，麦克风距离和电话编解码器）。



图1给出了此调查的概述以及要解决的关键问题。图中还显示了每个问题的子方面。在第2-6节中讨论了这七个关键问题及其子方面。



典型SER的完整流水线如图2所示。整个流水线分为三个部分：特征（在第4节中描述），模型（在第5节中描述）和测试。特征在训练和测试阶段都是通用的。特征部分包括三个步骤：预处理，特征提取和特征选择。预处理用于对语音进行降噪并查找显着片段。特征提取是确定与不同情绪相对应的辨别特征的必要步骤。语音信号是非平稳的，因此，首先提取帧级（局部）特征，然后将统计描述符应用于全局特征。使用训练集中说话者的统计信息，对生成的特征进一步进行标准化，以实现与说话者无关的情感识别。特征选择策略通过选择非冗余和相关特征来防止模型遭受维数的困扰。模型部分使用常规模型或基于深度学习的模型。基于深度学习的模型需要最少的信号处理，因为全局特征是由模型本身学习的。事实证明，分层分类器可以为常规模型[33-35]产生良好的效果，也可以应用于基于深度学习的模型。由于说话者，文本和语言的不匹配，测试数据的分布与训练数据的分布不同。因此，在测试阶段之前，需要通过测试数据对现有模型进行调整。虚线框显示通常是可选的步骤，但是在自然环境中必须执行这些步骤才能获得更好的情感识别精度。



本文的其余部分按以下方式组织：在第2节中，讨论了不同类型的数据库以及它们的优缺点。第3节描述了怎样对情绪进行建模。第4节讨论了语音情感识别的预处理，特征和特征选择算法。在第5节中，将详细讨论不同的分类器技术及其优缺点。还详细讨论了深度学习技术，它们的问题以及相关的解决方案。第6节讨论与人为因素（说话者，文本和语言）和录音环境（噪声，麦克风，编解码器不匹配等）引起的环境不匹配有关的技术。第7节讨论了用于评估模型的评估指标。第8节总结了调查，并指出了自然环境中SER的进一步工作范围。

## 2. 数据库

自动语音情感识别的一个主要问题是收集合适的数据来训练模型。基于情感语音是如何产生的，情感语音数据库被分为三组[12]: (1)扮演的，(2)诱发的，和(3)自然的。表2总结了每种数据库的优缺点。由于非自然的原因，已经简要地讨论了扮演型数据库和诱发数据库，但是已经更详细地讨论了适合于自然环境中的SER的自然数据库。

1. 行为数据库:行为数据库是从有经验的专业艺术家那里收集的。它们是标准的、最常用的情感数据库。情绪的完整范围是可用的，结果可以很容易地比较。这些数据库包含高质量的音频，它们避免了录音问题，如麦克风距离、编解码器效果、噪音和混响数据。当训练和测试在同一个数据库上执行时，SER的准确性达到最佳。然而，当在不同的数据库上执行训练和测试时，准确性显著降低。最近，人们提出了各种方法来解决这个问题。在第6节中，讨论了与语言无关的情感识别相关的技术。

2. 诱发数据库:诱发情绪语音数据库是通过生成情绪情境来收集的。在这里，说话者与锚交谈，锚产生各种语境状态，在说话者体内产生诱导情绪，这种情绪反映在说话者的言语中。这可能不会产生所有类别的情绪。这些数据库接近自然数据库，并包含上下文信息，然而，上下文是人为的。塔瓦里和特里维迪[36]研究语境在语音情感识别中的作用。

3. 自然数据库:自然数据库是自然表达的，对现实世界的情感建模很有用。这些数据库是通过呼叫中心对话、驾驶舱录音、病人-医生对话和公共场所录音收集的。还是那句话，这些未必包含全部情绪。与自然数据库相关的问题是版权和隐私问题、不受控制的噪音、重叠的谈话以及多种情绪的同时出现。

