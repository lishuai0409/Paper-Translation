# CMAR:基于多类关联规则的准确高效分类

Wenmin Li   Jiawei Han   Jian Pei

## 摘要

以往的研究表明，关联分类在处理非结构化数据时具有较高的分类精度和较强的灵活性。
然而，由于分类仅基于单个高置信度规则，因此它仍然受到大量挖掘规则的困扰，并且有时会出现有偏的分类或过拟合。

在本研究中，我们提出了一种新的关联分类方法CMAR，即基于多重关联规则的分类。
该方法扩展了一种高效的频繁模式挖掘方法——FP-growth，构造了一个类分布关联的FP-tree，有效地挖掘了大型数据库。
此外，该算法采用CR-tree结构高效地存储和检索挖掘出的关联规则，并基于置信度、相关性和数据库覆盖率有效地剪枝规则。分类是基于使用多个强关联规则的加权$\chi^2$分析来执行的。
我们在UCI机器学习数据库中的26个数据库上进行的大量实验表明，与CBA和C4.5相比，CMAR在对各种类型的数据库进行分类时是一致的、高效的，并且具有更好的平均分类精度。
此外，我们的性能研究表明，与其他已报道的关联分类方法相比，该方法是高效的和可扩展的。

## 1 引言

为大型数据库建立准确高效的分类器是数据挖掘和机器学习研究的基本任务之一。
给定一组以类标签为训练集的案例，分类就是建立一个模型(称为分类器)来预测类标签未知的未来数据对象。
先前的研究已经开发了用于构建分类器的启发式/贪心搜索技术，例如决策树[10]、规则学习[2]、朴素贝叶斯分类[4]和统计方法[8]。
这些技术从用于质量预测的训练数据集归纳出规则的代表性子集(例如，决策树或一组规则)。

最近的研究建议从训练数据集中提取一组高质量的关联规则，这些规则满足特定的用户指定的频率和置信度阈值。
通过仔细选择规则，例如CBA[9]，CAEP[3]和ADT[11]，已经建立了有效且高效的分类器。
这种方法从为分类而挖掘的所有规则中选取最有效的规则。
因为关联规则探索多个变量之间的高度自信的关联，所以它可以克服由一次检查一个变量的决策树归纳方法引入的一些约束。
广泛的性能研究[6，9，3，11]表明，基于关联的分类通常具有更好的准确性。
然而，如下所示，这种方法也有一些缺点。

一方面，要确定最有效的新案例分类规则并不容易。
有些方法，如[9，3，11]，只是选择一个具有最大用户定义度量的规则，如置信度。
正如我们将在后面看到的，在许多情况下，这样的选择并不总是正确的选择。
如此简单的挑选可能会影响分类的准确性。

另一方面，一个训练数据集通常会产生一套庞大的规则。
高效地存储、检索、删减和分类大量规则是一个挑战。
许多研究[1，5]表明了频繁模式的组合爆炸数的固有性质，因此当支持阈值很小时(即，当罕见情况也包括在考虑范围内时)，可以生成关联规则。
为了获得高精度，分类器可能需要处理大量规则，包括存储关联挖掘方法生成的规则，检索相关规则，以及对大量规则进行筛选和排序。

能否解决以上两个问题？
为了解决第一个问题，即准确地预测一个新的案例，而不是只应用一个规则，人们可以考虑最相关的、高度自信的规则的一个小子集，并做出集体的、全面的决定。
直觉上，这将有助于我们避免偏差、异常和过拟合过小的数据集。
为了克服第二个问题，即基于关联的分类的效率和可扩展性问题，人们需要开发有效的方法来存储和检索规则。
这可能有助于提高效率以及分类的准确性，因为可以存储和考虑更多的规则。
这就是本研究的动机。

在本文中，我们开发了一种新的技术，CMAR，用于准确和有效的分类，并做出以下贡献。

首先，CMAR不是依赖单一的分类规则，而是通过一组规则来确定类别标签。
给定一个新的预测案例，CMAR选择一小组高置信度、高度相关的规则，并分析这些规则之间的相关性。
为了避免偏差，我们开发了一种称为加权$\chi^2$的新技术，它可以很好地衡量规则在条件支持和类别分布下的强度。
广泛的性能研究表明，CMAR总体上比CBA[9]和C4.5[10]具有更高的预测精度。

第二，为了提高准确性和效率，CMAR采用了一种新的数据结构，CR-tree，来紧凑地存储和高效地检索大量的分类规则。
CR-tree是一种前缀树结构，用于探索规则之间的共享，实现了实质上的紧凑性。
CR-tree本身也是规则的索引结构，可以有效地服务于规则检索。

第三，为了加快整套规则的挖掘，CMAR采用了最近开发的FP-growth方法的变体。
FP-growth比以前基于关联的分类中使用的类似Apriori的方法(如[9，3，11])快得多，尤其是当存在大量规则、大量训练数据集和长模式规则时。

论文的其余部分安排如下。第二节重温了联想分类的一般思想。第3节致力于分类规则的生成。第4节讨论了如何使用生成的规则对新的数据对象进行分类。第5节报告了分类精度的实验结果以及效率和可扩展性的性能研究。论文在第6节结束。

## 2 关联分类

假设数据对象$obj=(a_1,...,a_n)$遵循模式$(A_1,...,A_n)$，其中$A_1,...,A_n$称为属性。
属性可以是分类的或连续的。
对于分类属性，我们假设所有可能的值都映射到一组连续的正整数。
对于一个连续型属性，我们假映射设它的取值范围离散化为区间，区间也为连续的正整数。
通过这样做，所有属性在本研究中都得到了统一处理。

设$ C= \{ c_1,...,c_m \} $是一组有限的类标签。
训练数据集是一组数据对象，使得对于每个对象$obj$，存在一个类标签$ c_{obj} \in C$与之关联。
分类器$\zeta$是一个从$(A_1,...,A_n)$到$C$的函数。
给定一个数据$obj$，$\zeta (obj) \in C$返回一个类标签。

一般来说，给定一个训练数据集，分类的任务是从训练数据集构建一个分类器，使得它可以用于以高精度预测未知对象的类别标签。

除了许多不同的分类方法，如决策树方法、朴素贝叶斯方法、k近邻方法、神经网络方法，一种新的方法是探索对象条件和类标签之间的关联关系[9]。
这个想法很自然，因为它利用训练数据集中案例和类标签之间的频繁模式和关联关系来进行分类。
如果在训练数据集中可以观察到一些频繁模式和类标签之间的强关联，则可以对相似模式的未来对象进行分类。

总的来说，一个模式 $P=a_{i_1}...a_{i_k} $是一组属性值，例如对于$(1 \leq j \leq k)$，$a_{i_j} \in A_{i_j}$并且$i_j \neq i_{j'}$，对于$j' \neq j$。
当且仅当对于$(1 \leq j \leq k)$，$obj$的值$a_{i_j}$属于$A_{i_j}$时，数据对象$obj$与模式$P=a_{i_1}...a_{i_k} $匹配。

给定一个训练数据集$T$，设$c$是一个类标签。
对于规则$ R:P \rightarrow c $，在数据集T中，符合模式P并且属于类别$c$的数据对象的数量称为R的支持度，表示为$sup(R)$.符合模式P并且类别标签是c的数据对象数量在总的符合模式P的数据对象中所占的比例称为R的置信度，表示为$conf(R)$。

例如，如果95%的顾客会因为没有工作而被限制不能得到超过3000美元的信用额度，即，规则R：$没有工作 \rightarrow 限制信用额度少于3000$的置信度为95%，
然后我们可以用规则R来对未来的数据对象进行分类。
为了避免噪声，只有当规则满足足够的支持度才能将它用于分类。
给定一个支持度阈值和一个置信度阈值，关联分类方法找到通过阈值的完整的类关联规则集。
当一个新的(未知的)对象到来时，分类器选择与数据对象相匹配并且具有最高置信度的规则，并使用它来预测新对象的类标签。

最近的研究表明，关联分类直观有效，在许多情况下具有良好的分类精度。
在大多数现有的关联分类方法[9，3，11]中，具有最高置信度的规则用于分类。
然而，这样的决定并不总是正确的。

例如，假设我们想用属性值来确定客户的信用额度$(没有工作，投资移民，海外资产 \geq 500k)$。
与客户匹配的置信度最高的3个规则如下。

$ \bullet 规则 R_1: 没有工作 \rightarrow 信用额度在3000^-$ （支持度：3000，置信度：95% ）；

$ \bullet 规则 R_2: 投资移民 \rightarrow 信用额度在3000^+ $ （支持度：5000，置信度：93% ）；

$ \bullet 规则 R_3: 海外资产 \geq 500k \rightarrow 信用额度在3000^+$ （支持度：8000，置信度：91%）。

那么，给定这样一个客户，我们应该预测什么样的类别标签呢？

传统的关联分类方法，例如CBA，可能会根据规则1的预测分类结果为信用额度在3000以下，因为规则一的置信度最高。
但是仔细看规则2和规则3可能我们会重新考虑这个决定。
这三个规则有相似的置信度，但是规则2和规则3有更高的支持度。
基于规则2和规则3的分类似乎更可靠。

上面的例子表明，为了做出可靠和准确的预测，最有信心的规则可能并不总是最佳选择，而基于多个规则的全面、详细和全面的度量分析可能导致更好的预测质量。

## 3 生成分类规则

在本节中，我们开发了一种新的关联分类方法，称为CMAR，它基于多个关联规则执行分类。

CMAR包括两个阶段:规则生成和分类。

在第一阶段，规则生成，CMAR以$ R: P \rightarrow c$的形式计算完整的规则集，其中，P是训练数据集中的一个模式，并且c是一个类标签，
这样$sup(R)$和$conf(R)$需要分别通过给定的支持度和置信度阈值。
此外，CMAR修剪了一些规则，只选择高质量规则的子集进行分类。

在第二阶段，分类，对于给定的数据对象$obj$，CMAR提取匹配该对象的规则子集，并通过分析该规则子集来预测该对象的类别标签。

在本节中，我们开发了生成分类规则的方法。
第二阶段，分类，将在第4节中讨论。

### 3.1 最小类关联规则支持和置信阈值

为了找到分类规则，CMAR首先挖掘训练数据集，以找到通过特定支持度和置信度阈值的完整规则集。
这是一个典型的频繁模式或关联规则挖掘任务[1]。
为了使挖掘变得可行和有效，CMAR采用了FP-growth 方法的一种变体[5]。
FP-growth是一种频繁模式挖掘算法，它比传统的类Apriori方法更快，特别是在存在大数据集、低支持度阈值和/或长模式的情况下。
CMAR采矿规则的总体思路如下例所示。

示例1(挖掘类关联规则)给定如表1所示的训练数据集$T$。
假设支持度阈值为$2$，置信度阈值为$50%$。CMAR挖掘分类-关联规则如下。

首先，CMAR扫描训练数据集$T$一次，找到在$$T中至少出现两次的属性值集合。
该集合是$F= \{ a_1,b_2,c_1,d_3 } $，被称为频繁项集。
所有未达到支持阈值的其他属性值不能在分类关联规则中起到任何作用，因此可以被删除。

然后，CMAR按照支持度对属性值进行降序排序，例如，$F-list : a_1-b_2-c_1-d_3 $。
然后，CMAR再次扫描训练数据集以构建FP树，如图1(a)所示。

FP-tree是关于F-list的前缀树。
对于训练数据集中的每个元组，出现在F-list中的属性值被提取出来，并根据F-list进行排序。
例如，对于第一个元组，$(a_1,c_1)$被提取并作为树中最左边的分支插入到树中。类别标签附加到路径中的最后一个节点。

训练数据集中的元组共享前缀。
例如，第二个元组携带F-list中的属性值$(a_1,b_2,c_1)$，并与第一个元组共享一个公共前缀$a_1$。
因此，它也与最远的分支共享$a_1$子路径。

所有具有相同属性值的节点被链接在一起，作为从标题表开始的队列。

第三，基于F-list，类关联规则集可以分成不重叠的4个子集:(1)具有$d_3$的子集；(2)有$c_1$但没有$d_3$的；(3)有$b_2$但是没有$d_3$也没有$c_1$；(4)只有$a_1$。
CMAR一个接一个地找到这些子集

第四，为了找到含有规则$d_3$的子集，CMAR遍历属性值为$d_3$的节点，然后向上寻找$d_3$投射的数据集，
该数据集包含了三个元组：$(a_1,b_2,c_1,d_3):C,(a_1,b_2,c_3):C,d_3:A$。
它包含了所有具有$d_3$的元组。
在整个训练集中找到所有具有$d_3$的频繁模式的问题可以简化为在$d_3$投影数据库中挖掘频繁模式。

递归下去，在$d_3$投影数据库中，$a_1$和$b_2$是频繁属性值，也就是说，他们通过了支持度门槛。
在$d_3$投影数据库中，$d_3$出现在每一个元组中，因此它是非常频繁的。我们不用把$d_3$作为一个本地频繁属性值。
我们可以通过FP-trees和投射的数据库来递归地挖掘投射数据库。详情请见[5]。

碰巧的是，在$d_3$的投射数据库中，$a_1$和$b_2$总是同时出现，因此$a_1 b_2$是一个频繁模式。
$a_1$和$b_2$是$a_1 b_2$的两个子模式，并且有着和$a_1 b_2$一样的支持度。
为了避免琐碎，我们只采用频繁模式$a_1 b_2 d_3$。
基于类别标签分布信息，我们产生了规则$a_1 b_2 d_3 \rightarrow C$，支持度为2，置信度为100%。

在搜索具有$d_3$的规则之后，$d_3$的所有节点被分别合并到它们的父节点中。也就是说，在$d_3$节点中注册的类标签信息在其父节点中注册。FP-tree被收缩，如图1(b)所示。
请注意，这个树收缩操作是在收集$d_3$投影数据库的同一扫描中完成的。

剩余的规则子集可以类似地被挖掘。

CMAR的规则挖掘和标准的FP-growth算法有两个主要区别。

一方面，CMAR一步找到频繁模式并生成规则。

传统上，关联规则的挖掘必须分两步进行[1]。
传统的关联分类方法也是如此[9]。
首先，找到所有的频繁模式(即通过支持阈值的模式)。然后，基于挖掘出的频繁模式生成所有满足置信度阈值的关联规则。

CMAR与其他关联分类方法的不同之处在于，对于每个模式，CMAR在与该模式匹配的数据对象之间维护各种类标签的分布。
这在计算(条件)数据库的过程中没有任何开销。因此，一旦发现频繁模式(即，模式通过支持阈值)，就可以立即生成关于该模式的规则。因此，CMAR没有单独的规则生成步骤。

另一方面，CMAR使用类标签分布来修剪。

对于任何频繁模式$P$，假设$c$是匹配的数据对象中最重要的类。
如果具有类别标签$c$并且匹配模式$P$的数据数量小于支持度的阈值，则不需要搜索任何$P$的超集$P'$，
因为满足$P' \rightarrow c$这种形式的任何规则都也不能满足支持度的阈值。

### 3.2在CR-tree中存储规则

一旦规则被生成，它就被存储在CR-tree中，它是一个前缀树结构。在下面的例子中，我们展示了CR-tree的一般思想。

例2 (CR-tree)挖掘一个训练数据集后，发现了4个规则，如表2所示。

一个CR-tree是由一组规则构建的，如图2所示，而构建过程解释如下。

CR-tree有一个根节点。出现在规则左侧的所有属性值都根据其出现频率进行排序，即最频繁出现的属性值最先出现。

第一个规则，$abc \rightarrow A$作为从根节点开始的路径被插入到树中。
类别标签以及规则的支持度和置信度表示为$(A,80,80%)$,在路径中的最后一个节点，即该规则的节点$c$处注册。

第二条规则，$abcd \rightarrow A$，与第一条规则共享一个前缀$abc$。
因此，通过将新节点$d$扩展到由第一个规则形成的路径，它被插入到树中。
同样，规则的类标签、支持和置信度在最后一个节点注册，即$d$。

第三和第四个规则可以类似地插入。
所有具有相同属性值的节点都通过节点链接链接到一个队列。
每个队列的头存储在一个头表中。

要存储原始规则集，规则的左侧需要13单元格。
使用CR-tree，只需要9个节点。

从上面的例子可以看出，CR-tree结构具有如下一些优点。

CR-tree是一种紧凑的结构。它探索了规则之间潜在的共享，因此可以节省大量存储规则的空间。
我们的实验结果表明，在许多情况下，使用CR-tree可以节约大约50%-60%的空间。

CR-tree本身就是规则的索引。
例如，如果我们想要检索所有具有属性值$b$和$d$的规则，并且在示例2中的规则集中，我们只需要遍历$d$的节点链接(从标题表开始),然后继续查找$b$。

一旦建立了关系树，规则检索就变得有效。这极大地简化了规则的剪枝和分类规则的使用。

### 3.3剪枝规则

由类关联规则挖掘生成的规则数量可能非常大。
为了使分类既有效又高效，我们需要修剪规则来删除冗余和有噪声的信息。

根据分类规则的便利性，组成了规则的全局顺序。
给定两个规则$R_1 和 R_2$，$R_1$比$R_2$的等级更高，记为$R_1 \geq R_2$，当且仅当

（1）$conf(R_1) \geq conf(R_2)$

（2）$conf(R_1) = conf(R_2)，但是 sup(R_1) \geq sup(R_2)$或者

（3）$conf(R_1) = conf(R_2),sup(R_1) =sup(R_2),但是R_1左边的属性值比R_2的少$

另外，当且仅当$P$是$P'$的子集时，称规则$R_1:P \rightarrow c$是一个关于$R_2:P' \rightarrow c'$的一般规则。

CMAR使用以下方法来修剪规则。

首先，使用一般和高置信度规则来修剪更具体和更低置信度的规则。

给定两个规则$R_1$和$R_2$，其中$R_1$是一个关于$R_2$的一般规则。
CMAR剪枝$R_2$，如果$R_1$有比$R_2$更高的等级。
其基本原理是，我们只需要考虑高置信度的一般规则，因此应该删减特定的低置信度规则。

当规则被插入到关系树中时，进行这种修剪。
当规则被插入到树中时，触发对树的检索，以检查该规则是否可以被删除，或者它是否可以删除已经插入的其他规则。
我们的实验结果表明这种修剪是有效的。

第二，只选择正相关的规则。
对于每一个规则$R:P \rightarrow c$，我们通过$\chi^2$测试来检验$P$是否与$c$是正相关关系。
只有规则是正相关关系，也就是说，它们的$\chi^2$值超过了显著性水平阈值，才能被用来进行后续的分类。
所有其他的规则都被剪枝。

这样做的基本原理是，我们使用规则来反映强大的应用程序来分类。
通过删除那些不正相关的规则，我们减少了噪音。

当发现一个规则时，就进行修剪。
由于类标签的分布在规则挖掘过程中会跟踪频繁模式，所以$\chi^2$测试几乎是免费的。

第三，基于数据库覆盖的剪枝规则。
CMAR选择高质量规则的子集进行分类。
这是通过基于数据库覆盖率修剪规则来实现的。
CMAR使用覆盖阈值[7]来选择数据库覆盖，如图3所示。

CMAR使用的数据库覆盖方法与美国中央银行相似。
主要区别在于，不是在某个数据对象被某个选定的规则覆盖后立即从训练数据集中移除该数据对象，而是让它停留在那里，直到它至少被$\delta$规则覆盖。
允许更多选定的规则。
当对一个新的数据对象进行分类时，它可能有更多的规则可供参考，并且可能有更好的机会被准确预测。

当规则挖掘过程完成时，将进行这种修剪。这是对规则的最后修剪。

## 4 基于多规则的分类

在选择了一套分类规则后，如第3节所讨论的，CMAR准备对新对象进行分类。
给定一个新的数据对象，CMAR从分类规则集中收集与新对象匹配的规则子集。
在本节中，我们将讨论如何基于规则子集来确定类标签。

显而易见，如果所有匹配新对象的规则都有相同的类标签，CMAR只需将该标签分配给新对象。

如果规则在类标签中不一致，CMAR根据类标签将规则分成组。
一个组中的所有规则共享相同的类标签，并且每个组都有不同的标签。
CMAR比较了这些群体的影响，并向最强的群体屈服。

要比较各组的强弱，需要衡量各组的“组合效应”。
直觉上，如果一个群体中的规则是高度正相关的，并且有很好的支撑，那么这个群体应该有很强的效果。

有许多方法可以衡量一组规则的综合效果。
比如可以用最强的规则作为代表。
也就是说，选择具有最高$\chi^2$值的规则。
然而，简单地选择$\chi^2$值最高的那一个可能对数量少的类别有好处，如下例所示。

基于观察值和期望值，$R_1$和$R_2$的$\chi^2$分别为88.4和33.6.
对于一个没有工作并且受过大学教育的客户，如果规则的选择仅基于$\chi^2$值，我们可以使用规则$R_1$来预测她的申请将被拒绝。

然而，从直觉上来说，规则$R_2$比$R_1$好得多，因为$R_2$有更高的支持度和信任度。

另一种选择是使用规则相关性的复合作为度量。例如，我们可以总结一个群体中的$\chi^2$值作为该群体的度量。然而，这种方法也存在同样的问题，即它可能过于偏向少数人。

一个更好的方法是将相关性和流行度的信息都集成到度量中。经验验证后，CMAR采用加权$\chi^2$度量[7],如下所示。

对于每一个规则$R:P \rightarrow c$,设$sup(c)$为训练数据集中与类标签$c$相关联的数据对象的数量，$|T|$为训练数据集中数据对象的数量。
定义规则$R$的$max \chi^2$如下。

$$
max \chi^2 = (min { sup(P),sup(c) } - \frac{sup(P)sup(c)}{|T|})^2 |T| e
$$

































